{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataWarehouse_QA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/EveryTimeIWill18/DataPiplines/blob/master/DataWarehouse_QA.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "glom0GUYBHjX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img height=\"60px\" src=\"https://pbs.twimg.com/profile_images/1006886947346964480/bChXq8_v_400x400.jpg\" align=\"left\" hspace=\"20px\" vspace=\"5px\">\n",
        "\n",
        "# Data Warehouse - QA\n",
        "---\n",
        "-  *This notebook will serve as the collaberative environment for all things related to the building of the data warehouse.*"
      ]
    },
    {
      "metadata": {
        "id": "cMORDGv9FJhs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Team Tasks\n",
        "---\n",
        "- ### __Will__:\n",
        "  - *Vailidating Charlie's method for ETL*.\n",
        "  - *Working on an automated version of Charlie's ETL process.*"
      ]
    },
    {
      "metadata": {
        "id": "se1SY9P2e24X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to Read in CSV Files\n",
        "---\n",
        "-  *Version 1*\n",
        "-  *Dependencies: __os__, __csv__ modules*.\n",
        "- *Output is a flattened list*"
      ]
    },
    {
      "metadata": {
        "id": "Q3xujQ2Le1BW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csv_processing(file: str, chunksize: int) -> list:\n",
        "    \"\"\"pre-process csv data\"\"\"\n",
        "    counter = 0\n",
        "    try:\n",
        "        if os.path.exists(file):\n",
        "            with open(file) as csvfile:\n",
        "                excel_file = csv.reader(csvfile, dialect='excel')\n",
        "                row_list = list()\n",
        "                for row in excel_file:\n",
        "                    row_list.append(row)\n",
        "                    counter += 1\n",
        "                    if counter >= chunksize:\n",
        "                        return list(chain.from_iterable(row_list))\n",
        "        else:\n",
        "            raise FileExistsError(\"Err: file not found\")\n",
        "    except FileExistsError as e:\n",
        "        return e\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3lBmebSLl4OV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Function to Read in CSV Files\n",
        "---\n",
        "-  *Version 2*\n",
        "-  *Dependencies: __os__, __csv__ modules*.\n",
        "- *Outputs a dictionary that can be easily turned into a pandas DataFrame*"
      ]
    },
    {
      "metadata": {
        "id": "Et9N8_4dl2el",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csv_processing(file: str, chunksize: int) -> dict:\n",
        "    \"\"\"pre-process csv data\"\"\"\n",
        "    counter = 0\n",
        "    try:\n",
        "        if os.path.exists(file):\n",
        "            with open(file) as csvfile:\n",
        "                excel_file = csv.reader(csvfile, dialect='excel')\n",
        "                if counter == 0:\n",
        "                    row_counter = 0\n",
        "                    for row in excel_file:\n",
        "                        row_dict = {d: [] for d in row}\n",
        "                        row_counter += 1\n",
        "                        if row_counter >= 1:\n",
        "                            break\n",
        "                    counter += 1\n",
        "                    if chunksize == 1:\n",
        "                        return row_dict\n",
        "                if counter > 1:\n",
        "                    for row in excel_file:\n",
        "                        current = row.split(\",\")\n",
        "                        for i, _ in enumerate(current):\n",
        "                            row_dict[list(row_dict.keys())[i]].append(current[i])\n",
        "                        counter += 1\n",
        "                    if counter >= chunksize:\n",
        "                        return row_dict\n",
        "        else:\n",
        "            raise FileExistsError(\"Err: file not found\")\n",
        "    except FileExistsError as e:\n",
        "        return e"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}